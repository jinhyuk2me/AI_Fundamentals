## TL;DR
- 베이지안 추론은 사전 분포(prior)와 데이터 우도(likelihood)를 결합해 사후 분포(posterior)를 구하고, 불확실성을 정량화한다.
- VAE, Bayesian Neural Network, Bayesian Optimization, Laplace Approximation 등 현대 DL 기법의 수학적 토대다.
- Exact inference가 어려운 경우 변분 추론(ELBO)이나 MCMC/Gibbs로 근사하며, PyTorch·Pyro·PyMC를 활용해 실습할 수 있다.

## 언제 쓰나
- 데이터가 적거나 불확실성이 중요한 안전·의료·추천 시스템에서 모델의 확신도를 평가할 때
- Neural Architecture에서 Dropout-as-Bayesian, Laplace Redux, SWAG 등의 불확실성 기법을 이해할 때
- Bayesian Optimization, Active Learning, Thompson Sampling 등 확률적 의사결정을 설계할 때
- Variational Autoencoder, Diffusion, Flow 모델처럼 사후 분포 근사와 KL 다이버전스를 다루는 경우

## 주요 API
| 개념/연산 | 정의 | PyTorch/라이브러리 포인트 |
| --- | --- | --- |
| 베이즈 정리 | $p(\theta \mid D) = \frac{p(D \mid \theta) p(\theta)}{p(D)}$ | Pyro `pyro.sample` / PyMC `pm.sample` |
| 켤레 사전 | 사전·우도가 같은 계열 → 사후 형태 유지 | Beta-Binomial, Normal-Normal, Gamma-Poisson |
| 변분 추론 | $\text{ELBO} = \mathbb{E}_{q} [\log p(D, \theta)] - \mathbb{E}_{q}[\log q(\theta)]$ | `torch.distributions`, Pyro `SVI` |
| MCMC | 사후에서 시퀀스를 샘플링 (Metropolis-Hastings, NUTS) | Pyro `HMCSample`, PyMC `pm.sample` |
| 깁스 샘플링 | 조건부 분포 교대로 샘플 | Pyro custom update, NumPy loop |
| Laplace Approx. | 사후를 정규분포로 2차 근사 | `laplace.torch` |
| Bayesian Linear Regression | closed form 사후 | `torch.linalg`로 사후 평균/공분산 계산 |

## 실습 예제
### 1. Beta-Binomial 업데이트 (케이스 스터디)
```python
import torch
alpha0, beta0 = 2., 2.
data = torch.tensor([1, 0, 1, 1, 0, 1])  # 1=성공, 0=실패
alpha_post = alpha0 + data.sum()
beta_post = beta0 + (len(data) - data.sum())
print(alpha_post, beta_post)  # posterior Beta
```
- 사후 기대값 $\mathbb{E}[\theta \mid D] = \frac{\alpha_{\text{post}}}{\alpha_{\text{post}} + \beta_{\text{post}}}$ 로 업데이트.
- 실행 결과 $\alpha_{\text{post}} = 6, \beta_{\text{post}} = 4$이며, 베르누이 성공 확률의 사후 평균은 $0.6$으로 MLE보다 보수적인 추정을 제공한다.

### 2. PyTorch로 변분 베이지안 선형 회귀 (ELBO)
```python
import math

X = [0.0, 1.0, 2.0, 3.0]
y = [0.05, 0.82, 1.55, 2.37]
sigma_noise = 0.3
Phi = [[x, 1.0] for x in X]
mu = [0.0, 0.0]
log_sigma = [0.0, 0.0]
lr = 1e-3
for step in range(100000):
    sigma = [math.exp(ls) for ls in log_sigma]
    preds = [mu[0]*row[0] + mu[1] for row in Phi]
    resid = [preds[i] - y[i] for i in range(len(y))]
    grad_mu = [
        -(sum(resid[i]*Phi[i][j] for i in range(len(y))) / (sigma_noise**2)) - mu[j]
        for j in range(2)
    ]
    diag_terms = [sum(Phi[i][j]**2 for i in range(len(y))) for j in range(2)]
    grad_log_sigma = [
        - (math.exp(2*log_sigma[j])) * (diag_terms[j]/(sigma_noise**2) + 1.0) + 1.0
        for j in range(2)
    ]
    mu = [mu[j] + lr * grad_mu[j] for j in range(2)]
    log_sigma = [log_sigma[j] + lr * grad_log_sigma[j] for j in range(2)]
posterior_std = [math.exp(ls) for ls in log_sigma]
print('posterior mean:', mu, 'posterior std:', posterior_std)
```
- Reparameterization trick 대신, 선형 회귀 + 정규 사전의 분석적 ELBO를 활용해 파라미터를 직접 최적화했다.
- 위 코드에서는 $\mu \approx (0.757, 0.061)$, 표준편차 $\sigma \approx (0.080, 0.148)$로 수렴해 참 계수(0.8, 0.1)에 근접함을 확인했다.

### 3. Pyro의 MCMC(NUTS)로 Bayesian Linear Regression
```python
import random, math

def log_prob(w0, w1):
    lp = -0.5*(w0**2 + w1**2)
    for xi, yi in zip(X, y):
        mean = w0*xi + w1
        lp -= 0.5*((yi-mean)/sigma_noise)**2
    return lp

w0 = w1 = 0.0
current = log_prob(w0, w1)
proposal_scale = 0.05
samples = []
for step in range(50000):
    cand0 = w0 + random.gauss(0, proposal_scale)
    cand1 = w1 + random.gauss(0, proposal_scale)
    cand_lp = log_prob(cand0, cand1)
    if math.log(random.random()) < cand_lp - current:
        w0, w1, current = cand0, cand1, cand_lp
    if step > 10000 and step % 10 == 0:
        samples.append((w0, w1))
mean_w0 = sum(s[0] for s in samples)/len(samples)
mean_w1 = sum(s[1] for s in samples)/len(samples)
print('posterior mean via MCMC:', mean_w0, mean_w1)
```
- 단순 Random-walk Metropolis-Hastings로 약 4k개의 샘플을 수집했으며, posterior mean은 $(0.754, 0.065)$로 변분 근사와 일치함을 확인했다.

### 4. Laplace Approximation (Laplace Redux)
```python
import torch
from laplace import Laplace

model = torch.nn.Sequential(torch.nn.Linear(1, 20), torch.nn.Tanh(), torch.nn.Linear(20, 1))
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), 1e-3)

for _ in range(1000):
    optimizer.zero_grad()
    loss = criterion(model(X), y.unsqueeze(-1))
    loss.backward(); optimizer.step()

la = Laplace(model, 'regression', subset_of_weights='all')
la.fit(X, y.unsqueeze(-1))
la.optimize_prior_precision()
preds_mean, preds_var = la(X_test, pred_type='nn')
```
- Laplace Redux는 학습된 MLP에 대한 사후 분산을 계산해 불확실성을 추정한다.

## 실수 주의
- 사전 분포를 지나치게 협소하게 두면 데이터가 충분해도 사후가 왜곡되어 underfitting이 발생한다.
- 변분 추론 시 ELBO 로그 우도에 scale 문제가 생기면 KL term이 지배하므로 mini-batch 시 `log_lik`을 재스케일해야 한다.
- MCMC는 burn-in, thinning, mixing diagnostics를 확인하지 않으면 수렴하지 않은 샘플로 판단 오류를 낼 수 있다.
- Laplace Approximation은 하나의 모드 근처 2차 근사이므로 multi-modal posterior에서는 적합하지 않을 수 있다.

## 관련 노트
- [[Math/Probability/2. 확률 기초]]
- [[Math/Probability/3. 통계적 추론]]
- [[Math/Probability/6. 확률 과정]]
- [[Math/Calculus/6. 벡터 미적분]]
- [[Math/Optimization/3. 2차 최적화 기법]]
- [[Foundations/7. 역전파와 최적화 전략]]
- [[Math/Math_확장_계획]]
